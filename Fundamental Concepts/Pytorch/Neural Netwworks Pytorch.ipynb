{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bf51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140caa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a792d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the model\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # This line is required for all Python classes!\n",
    "    \n",
    "        # Define the model here\n",
    "        self.middle_layer = nn.Linear(3, 4)\n",
    "        self.final_layer = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # return the prediction here\n",
    "        intermediate = self.middle_layer.forward(x)\n",
    "        return self.final_layer.forward(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd2d8af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (middle_layer): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (final_layer): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleModel()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa1de651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.4816975593566895\n"
     ]
    }
   ],
   "source": [
    "# Das ist eine einfache Lineare Lösung\n",
    "\n",
    "data_point = torch.tensor([45, 1.5, 1.7]) # Dimension very important Eingabe (3,)\n",
    "true_answer  = torch.tensor(0.75)                 # Ziel als Skalar\n",
    "\n",
    "prediction = model(data_point)  # Forward function is calling\n",
    "\n",
    "print(prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5295f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer und hyperparameter\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "num_it = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68bb8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171642/4073018911.py:6: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  error = nn.functional.mse_loss(pred, true_answer) # 3) Error (Loss)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100: loss=0.000000, pred=0.7500\n",
      " 200: loss=0.000000, pred=0.7500\n",
      " 300: loss=0.000000, pred=0.7500\n",
      " 400: loss=0.000000, pred=0.7500\n",
      " 500: loss=0.000000, pred=0.7500\n",
      " 600: loss=0.000000, pred=0.7500\n",
      " 700: loss=0.000000, pred=0.7500\n",
      " 800: loss=0.000000, pred=0.7500\n",
      " 900: loss=0.000000, pred=0.7500\n",
      "1000: loss=0.000000, pred=0.7500\n"
     ]
    }
   ],
   "source": [
    "# 2 Training\n",
    "\n",
    "for i in range(num_it):\n",
    "    optimizer.zero_grad()                     # 1) Gradienten zurücksetzen\n",
    "    pred = model(data_point)                  # 2) Vorwärts (Predictions)\n",
    "    error = nn.functional.mse_loss(pred, true_answer) # 3) Error (Loss)\n",
    "    error.backward() # we use the error und calculte the derivative\n",
    "    \n",
    "    # use the derivative to update the parameter\n",
    "    optimizer.step() # Update\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"{i+1:4d}: loss={error.item():.6f}, pred={pred.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b550ed",
   "metadata": {},
   "source": [
    "## copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebebc06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100: loss=0.000000, pred=0.7500\n",
      " 200: loss=0.000000, pred=0.7500\n",
      " 300: loss=0.000000, pred=0.7500\n",
      " 400: loss=0.000000, pred=0.7500\n",
      " 500: loss=0.000000, pred=0.7500\n",
      " 600: loss=0.000000, pred=0.7500\n",
      " 700: loss=0.000000, pred=0.7500\n",
      " 800: loss=0.000000, pred=0.7500\n",
      " 900: loss=0.000000, pred=0.7500\n",
      "1000: loss=0.000000, pred=0.7500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Model wie vorher ---\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.middle_layer = nn.Linear(3, 4)\n",
    "        self.final_layer  = nn.Linear(4, 1)\n",
    "    def forward(self, x):\n",
    "        return self.final_layer(self.middle_layer(x))\n",
    "\n",
    "model = SimpleModel()\n",
    "model.train()\n",
    "\n",
    "# --- Daten ---\n",
    "x = data_point.unsqueeze(0)      # (1,3)\n",
    "y = true_answer.unsqueeze(0).unsqueeze(1)  # (1,1)\n",
    "\n",
    "# --- Optimizer & Hyperparameter ---\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "num_it = 1000\n",
    "\n",
    "for i in range(num_it):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(x)              # (1,1)\n",
    "    loss = nn.functional.mse_loss(pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"{i+1:4d}: loss={loss.item():.6f}, pred={pred.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1caf0a6",
   "metadata": {},
   "source": [
    "## Model testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32abcff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (middle_layer): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (final_layer): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c9557ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage: 0.5990891456604004\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_point = torch.tensor([50.0, 2.0, 1.0]).unsqueeze(0)  # (1,3)\n",
    "    prediction = model(test_point)\n",
    "    print(\"Vorhersage:\", prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21459807",
   "metadata": {},
   "source": [
    "### Loss auf Testdaten messen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a05e6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.02277408540248871\n"
     ]
    }
   ],
   "source": [
    "true_answer_test  = torch.tensor(0.75)  \n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_test = model(test_point)\n",
    "    loss_test = nn.functional.mse_loss(pred_test, true_answer_test.unsqueeze(0).unsqueeze(1))\n",
    "    print(\"Test Loss:\", loss_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167305f8",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a1b86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In PyTorch speichert man normalerweise nur die Gewichte (state_dict), nicht das ganze Modellobjekt.\n",
    "torch.save(model.state_dict(), \"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Komplettes Modell speichern (seltener empfohlen)\n",
    "torch.save(model, \"simple_model_full.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543da2a8",
   "metadata": {},
   "source": [
    "## Model hochladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfab449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neues Modell mit gleicher Architektur erstellen\n",
    "model2 = SimpleModel()\n",
    "\n",
    "# Gewichte laden\n",
    "model2.load_state_dict(torch.load(\"simple_model.pth\"))\n",
    "\n",
    "# In den Evaluationsmodus setzen\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = torch.load(\"simple_model_full.pth\")\n",
    "model3.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d5868",
   "metadata": {},
   "source": [
    "* torch.save(model.state_dict()) → saubere Variante (empfohlen).\n",
    "\n",
    "* torch.save(model) → nur für schnelle Tests, aber weniger portabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566b247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
